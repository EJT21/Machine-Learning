{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd4d0a51-eefe-4e2f-be4e-daa3d60d72d5",
   "metadata": {},
   "source": [
    "## Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2a6f6403-860d-4085-8ad9-e0721fb953f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.utils import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding # Taking sequences of integers, and coming up as word vectors\n",
    "from keras.layers import SimpleRNN\n",
    "from keras.datasets import imdb\n",
    "from keras import initializers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b38723-996b-4855-9234-0bfd9775ab4c",
   "metadata": {},
   "source": [
    "#### This dataset contains data from IMBD on movie reviews. The training and test data both contain 25k rows. Based on the words used in the movie review, we will predict if it is a positive or negative rating. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3bebdea7-9549-40fd-b886-831e5d6daf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 20000  # This is used in loading the data, picks the most common (max_features) words\n",
    "maxlen = 30  # maximum length of a sequence - truncate after this. IE only use 30 words\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3483dddd-bc6e-445f-959a-4913e800fd2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 train sequences\n",
      "25000 test sequences\n"
     ]
    }
   ],
   "source": [
    "## Load in the data.  The function automatically tokenizes the text into distinct integers\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_features) #pulling from API\n",
    "print(len(X_train), 'train sequences')\n",
    "print(len(X_test), 'test sequences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "372f2e2d-a9cd-4955-9d97-cc24977f058d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "efb267f1-7129-43b0-872a-8bbecae2b227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (25000, 30)\n",
      "x_test shape: (25000, 30)\n"
     ]
    }
   ],
   "source": [
    "# This pads (or truncates) the sequences so that they are of the maximum length\n",
    "X_train = pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, maxlen=maxlen)\n",
    "print('x_train shape:', X_train.shape)\n",
    "print('x_test shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc3d2962-7c13-4da9-b387-003bc980fc9c",
   "metadata": {},
   "source": [
    "#### Lets look at an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f257ff1-d2f8-4785-ba93-79b4185682e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  219,   141,    35,   221,   956,    54,    13,    16,    11,\n",
       "        2714,    61,   322,   423,    12,    38,    76,    59,  1803,\n",
       "          72,     8, 10508,    23,     5,   967,    12,    38,    85,\n",
       "          62,   358,    99], dtype=int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[123,:] "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2927d87-73c5-43cb-8216-e3db77a88b68",
   "metadata": {},
   "source": [
    "#### For the 30 words used here, the first word was used 219 times the second 141, and so on"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddfcc90b-50f4-45ee-b3f5-40b8d1dc347e",
   "metadata": {},
   "source": [
    "#### Now lets build a RNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e3a2f2c6-09ef-46a6-a5e2-487e531a791b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_hidden_dim = 5      #we will use five hiden layers, arbitrary number\n",
    "word_embedding_dim = 50 #vector that has 50 numbers, this is used to find similar words. Example hot and boiling are similar\n",
    "model_rnn = Sequential()\n",
    "model_rnn.add(Embedding(max_features, word_embedding_dim))  #This layer takes each integer in the sequence and embeds it in a 50-dimensional vector. This is so we find similar words\n",
    "model_rnn.add(SimpleRNN(rnn_hidden_dim,\n",
    "                    kernel_initializer=initializers.RandomNormal(stddev=0.001), #weights for the input, we randomize them and let the RNN figure out how to adjust\n",
    "                    recurrent_initializer=initializers.Identity(gain=1.0),      #weights for each state layer\n",
    "                    activation='relu', #relu works best, tanh also is good\n",
    "                    input_shape=x_train.shape[1:])) #specifiy the shape of the input\n",
    "\n",
    "model_rnn.add(Dense(1, activation='sigmoid')) # output Nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "987e8675-02a0-4d46-84e3-83b65bdf3b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, None, 50)          1000000   \n",
      "                                                                 \n",
      " simple_rnn (SimpleRNN)      (None, 5)                 280       \n",
      "                                                                 \n",
      " dense (Dense)               (None, 1)                 6         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,000,286\n",
      "Trainable params: 1,000,286\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_rnn.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "57da1287-1f23-4ac6-a315-dd03688b3ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsprop = keras.optimizers.RMSprop(learning_rate = .0001) #Hyperparamater for learning rate\n",
    "#more info can be found here on this https://keras.io/api/optimizers/rmsprop/\n",
    "model_rnn.compile(loss='binary_crossentropy',optimizer=rmsprop,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "77533892-c345-4ca2-9817-90d424c7c1ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.6485 - accuracy: 0.6326 - val_loss: 0.5887 - val_accuracy: 0.6896\n",
      "Epoch 2/20\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.5372 - accuracy: 0.7299 - val_loss: 0.5300 - val_accuracy: 0.7297\n",
      "Epoch 3/20\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.4788 - accuracy: 0.7724 - val_loss: 0.4967 - val_accuracy: 0.7544\n",
      "Epoch 4/20\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.4411 - accuracy: 0.7961 - val_loss: 0.4770 - val_accuracy: 0.7662\n",
      "Epoch 5/20\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.4143 - accuracy: 0.8112 - val_loss: 0.4654 - val_accuracy: 0.7742\n",
      "Epoch 6/20\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.3955 - accuracy: 0.8217 - val_loss: 0.4552 - val_accuracy: 0.7795\n",
      "Epoch 7/20\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.3814 - accuracy: 0.8291 - val_loss: 0.4507 - val_accuracy: 0.7848\n",
      "Epoch 8/20\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.3713 - accuracy: 0.8348 - val_loss: 0.4515 - val_accuracy: 0.7840\n",
      "Epoch 9/20\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.3626 - accuracy: 0.8392 - val_loss: 0.4507 - val_accuracy: 0.7894\n",
      "Epoch 10/20\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.3567 - accuracy: 0.8433 - val_loss: 0.4513 - val_accuracy: 0.7882\n",
      "Epoch 11/20\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.3515 - accuracy: 0.8457 - val_loss: 0.4483 - val_accuracy: 0.7910\n",
      "Epoch 12/20\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3467 - accuracy: 0.8483 - val_loss: 0.4520 - val_accuracy: 0.7904\n",
      "Epoch 13/20\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3432 - accuracy: 0.8509 - val_loss: 0.4560 - val_accuracy: 0.7900\n",
      "Epoch 14/20\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3395 - accuracy: 0.8518 - val_loss: 0.4526 - val_accuracy: 0.7909\n",
      "Epoch 15/20\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3365 - accuracy: 0.8542 - val_loss: 0.4539 - val_accuracy: 0.7890\n",
      "Epoch 16/20\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3334 - accuracy: 0.8553 - val_loss: 0.4554 - val_accuracy: 0.7886\n",
      "Epoch 17/20\n",
      "782/782 [==============================] - 6s 8ms/step - loss: 0.3312 - accuracy: 0.8571 - val_loss: 0.4545 - val_accuracy: 0.7907\n",
      "Epoch 18/20\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3281 - accuracy: 0.8573 - val_loss: 0.4594 - val_accuracy: 0.7914\n",
      "Epoch 19/20\n",
      "782/782 [==============================] - 5s 7ms/step - loss: 0.3263 - accuracy: 0.8591 - val_loss: 0.4559 - val_accuracy: 0.7903\n",
      "Epoch 20/20\n",
      "782/782 [==============================] - 6s 7ms/step - loss: 0.3238 - accuracy: 0.8593 - val_loss: 0.4580 - val_accuracy: 0.7898\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f87d4151f10>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rnn.fit(X_train, y_train,batch_size=batch_size,epochs=20,validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d22e2259-f26a-4b6e-aa46-934b58f9cd89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 1s 1ms/step - loss: 0.4580 - accuracy: 0.7898\n",
      "Test score: 0.4580361843109131\n",
      "Test accuracy: 0.7898399829864502\n"
     ]
    }
   ],
   "source": [
    "score, acc = model_rnn.evaluate(X_test, y_test,batch_size=batch_size)\n",
    "print('Test score:', score) #binary cross entropy loss\n",
    "print('Test accuracy:', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42db2b5a-4e38-4115-973a-5516123339d9",
   "metadata": {},
   "source": [
    "#### Lets now try a more complex model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b3042ab4-f3d1-418c-a005-ef71269c42dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = 20000  # This is used in loading the data, picks the most common (max_features) words\n",
    "maxlen = 80  # maximum length of a sequence - truncate after this\n",
    "\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=max_features)\n",
    "\n",
    "X_train = pad_sequences(X_train, maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, maxlen=maxlen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "137fadba-b7f0-403c-8f74-5b64b072f6cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (25000, 80)\n",
      "X_train shape: (25000, 80)\n"
     ]
    }
   ],
   "source": [
    "print('X_train shape:', X_train.shape)\n",
    "print('X_train shape:', X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "816e5680-5b28-412e-bd2f-aaae7203bade",
   "metadata": {},
   "source": [
    "#### Build another RNN, using same paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "79b7e82e-ee41-4fea-b77d-b501bb117672",
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_hidden_dim = 5\n",
    "word_embedding_dim = 20\n",
    "model_rnn = Sequential()\n",
    "model_rnn.add(Embedding(max_features, word_embedding_dim))  #This layer takes each integer in the sequence\n",
    "model_rnn.add(SimpleRNN(rnn_hidden_dim,\n",
    "                    kernel_initializer=initializers.RandomNormal(stddev=0.001),\n",
    "                    recurrent_initializer=initializers.Identity(gain=1.0),\n",
    "                    activation='relu',\n",
    "                    input_shape=x_train.shape[1:]))\n",
    "\n",
    "model_rnn.add(Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2a72bb18-0bea-4bad-9425-990aea213144",
   "metadata": {},
   "outputs": [],
   "source": [
    "rmsprop = keras.optimizers.RMSprop(learning_rate = .0001)\n",
    "\n",
    "model_rnn.compile(loss='binary_crossentropy',optimizer=rmsprop,metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "04e8c98c-6fae-439e-8025-ab21435b361d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 5s 6ms/step - loss: 0.6881 - accuracy: 0.5104 - val_loss: 0.6744 - val_accuracy: 0.5159\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.6471 - accuracy: 0.6130 - val_loss: 0.6316 - val_accuracy: 0.6638\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.5967 - accuracy: 0.7171 - val_loss: 0.5662 - val_accuracy: 0.7111\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.5134 - accuracy: 0.7495 - val_loss: 0.5219 - val_accuracy: 0.7367\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.4671 - accuracy: 0.7810 - val_loss: 0.4916 - val_accuracy: 0.7590\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.4380 - accuracy: 0.7989 - val_loss: 0.4744 - val_accuracy: 0.7701\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.4178 - accuracy: 0.8101 - val_loss: 0.4637 - val_accuracy: 0.7764\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.4022 - accuracy: 0.8186 - val_loss: 0.4587 - val_accuracy: 0.7804\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3901 - accuracy: 0.8240 - val_loss: 0.4517 - val_accuracy: 0.7843\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 4s 5ms/step - loss: 0.3804 - accuracy: 0.8298 - val_loss: 0.4527 - val_accuracy: 0.7831\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f87cddb2250>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rnn.fit(X_train, y_train,batch_size=batch_size,epochs=10,validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "dd4b0750-1886-438d-9b17-0c55716d6b17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "782/782 [==============================] - 10s 12ms/step - loss: 0.4613 - accuracy: 0.8414 - val_loss: 0.5607 - val_accuracy: 0.7693\n",
      "Epoch 2/10\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.3212 - accuracy: 0.8634 - val_loss: 0.4263 - val_accuracy: 0.8091\n",
      "Epoch 3/10\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.2994 - accuracy: 0.8738 - val_loss: 0.3527 - val_accuracy: 0.8453\n",
      "Epoch 4/10\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.2868 - accuracy: 0.8798 - val_loss: 0.3683 - val_accuracy: 0.8388\n",
      "Epoch 5/10\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.2773 - accuracy: 0.8865 - val_loss: 0.3548 - val_accuracy: 0.8444\n",
      "Epoch 6/10\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.2684 - accuracy: 0.8886 - val_loss: 0.3530 - val_accuracy: 0.8471\n",
      "Epoch 7/10\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.2620 - accuracy: 0.8931 - val_loss: 0.3607 - val_accuracy: 0.8426\n",
      "Epoch 8/10\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.2559 - accuracy: 0.8958 - val_loss: 0.3526 - val_accuracy: 0.8492\n",
      "Epoch 9/10\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.2504 - accuracy: 0.8982 - val_loss: 0.3456 - val_accuracy: 0.8505\n",
      "Epoch 10/10\n",
      "782/782 [==============================] - 9s 12ms/step - loss: 0.2473 - accuracy: 0.9003 - val_loss: 0.3552 - val_accuracy: 0.8451\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f87b32559a0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_rnn.fit(X_train, y_train,batch_size=batch_size,epochs=10,validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ffcce0d-1420-4b76-8a81-a0a8b954e365",
   "metadata": {},
   "source": [
    "#### Conclusion: Given data on movie reviews, I was able to create a RNN model to predict whether it was a positive or negative review with 90% accurary. This is a lot better than a random guess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "dd3ffadb-2a03-4283-9826-b38fb18e9b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 [==============================] - 2s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = model_rnn.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a4e0cfa9-8656-4316-92ac-82b430eb45fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.9958018], dtype=float32)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred[1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

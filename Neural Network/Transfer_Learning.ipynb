{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6506279d-719a-465a-90ac-fc7a3273752a",
   "metadata": {},
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a4da34ea-2e86-4a15-8ee0-55d6f6df9cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0c4fc0-da3b-42db-8532-10825462f5fd",
   "metadata": {},
   "source": [
    "For this exercise, we will use the mnist dataset. This dataset has digits from 0-9 which we will attempt to classift given their images in the form of a array. The goal of transfer learning is to teach a model something, and see how the model transfers its knowledge to learn another thing with \n",
    "greater accuracy. For this example, I will train a model on the numbers 5-9, then train the last layer with the numbers 0-4 and see how accuractly it can classify 0-4. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1701f9c-a6f3-484d-845f-fcf85560d114",
   "metadata": {},
   "source": [
    "### Creating a method for building a CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "46a08435-ecc3-4210-94fd-56e61596bed2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#These are paramters that we will hypertune for the model\n",
    "batch_size = 128\n",
    "num_classes = 5\n",
    "epochs = 5 \n",
    "\n",
    "img_rows, img_cols = 28, 28\n",
    "filters = 32\n",
    "pool_size = 2\n",
    "kernel_size = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69ae9f84-7ec7-4004-855b-f8b402387c85",
   "metadata": {},
   "source": [
    "***Creating a function that creates a model and has three inputs:***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd00d5ec-2be1-4462-a84e-0caa56205c8d",
   "metadata": {},
   "source": [
    "1. Model\n",
    "2. Train set\n",
    "3. Test set \n",
    "4. The amount of classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8f051035-544d-42d5-865d-7f5ead89d3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "now = datetime.datetime.now  # Used to record time for training and testing\n",
    "def train_model(model, train, test, num_classes):\n",
    "    X_train = train[0].reshape((train[0].shape[0],) + input_shape) #Reshaping our nn \n",
    "    X_test = test[0].reshape((test[0].shape[0],) + input_shape)\n",
    "    X_train = X_train.astype('float32')\n",
    "    X_test = X_test.astype('float32')\n",
    "    X_train /= 255  #Scaling\n",
    "    X_test /= 255\n",
    "    print('X_train shape:', X_train.shape)\n",
    "    print(X_train.shape[0], 'train samples') #The amount of training samples in the dataset\n",
    "    print(X_test.shape[0], 'test samples') #The amount of test samples in the dataset\n",
    "\n",
    "    # turning our output into a OneHotEncoded array, this helps with accuracy\n",
    "    y_train = keras.utils.to_categorical(train[1], num_classes)\n",
    "    y_test = keras.utils.to_categorical(test[1], num_classes)\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adadelta',metrics=['accuracy'])\n",
    "\n",
    "    t = now()\n",
    "    model.fit(X_train, y_train,batch_size=batch_size,epochs=epochs,verbose=1,validation_data=(X_test, y_test))\n",
    "    print('Training time: %s' % (now() - t))\n",
    "\n",
    "    score = model.evaluate(X_test, y_test, verbose=1)\n",
    "    print('Test score:', score[0])\n",
    "    print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ee0715c-e3af-49fc-a72a-cf15adc4fffd",
   "metadata": {},
   "source": [
    "### Lets test this model on the mnist data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ff89f87d-64b6-486d-abbe-38f2cb8e4d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8a8b59e4-a1c0-4e4c-a638-6178bc53b0bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Digits 0-4\n",
    "X_train_lt5 = X_train[y_train < 5] #lt = less than \n",
    "y_train_lt5 = y_train[y_train < 5]\n",
    "X_test_lt5 = X_test[y_test < 5]\n",
    "y_test_lt5 = y_test[y_test < 5]\n",
    "\n",
    "#Digits 5-9\n",
    "X_train_gte5 = X_train[y_train >= 5] #gte = greater than 5\n",
    "y_train_gte5 = y_train[y_train >= 5] - 5\n",
    "X_test_gte5 = X_test[y_test >= 5]\n",
    "y_test_gte5 = y_test[y_test >= 5] - 5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4dfbd027-1a78-45f5-b24b-e1f1e78261ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4, 0, ..., 4, 0, 1], dtype=uint8)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_gte5 #This is so we can get the actual rows with numbers 5-9, but we want the values of 0-4 since this is what we are classifying"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "575d935e-2fd1-460b-8ec8-43b02b2b72d0",
   "metadata": {},
   "source": [
    "#### Creating the convolutional layer, flattening the image, adding dropout and activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c1a74956-4f31-43fa-944f-0229e37e8c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (28, 28, 1)\n",
    "feature_layers = [Conv2D(filters, kernel_size,padding='valid',input_shape=input_shape), Activation('relu'),\n",
    "    Conv2D(filters, kernel_size),Activation('relu'),MaxPooling2D(pool_size=pool_size),Dropout(0.25),Flatten(),]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "196f6ed4-c8ff-4d5b-b6f9-6006ebe5e95b",
   "metadata": {},
   "source": [
    "#### Creating the output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e430681c-5854-48d8-ad55-adbef1c5eab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_layers = [Dense(128),Activation('relu'),Dropout(0.2),Dense(num_classes),Activation('softmax')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "13765db9-158d-46e1-a4a1-681a6cfd5509",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential(feature_layers + classification_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "5c5b1be5-d6b3-4483-9a26-59358711ffe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_4 (Conv2D)           (None, 26, 26, 32)        320       \n",
      "                                                                 \n",
      " activation_8 (Activation)   (None, 26, 26, 32)        0         \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 24, 24, 32)        9248      \n",
      "                                                                 \n",
      " activation_9 (Activation)   (None, 24, 24, 32)        0         \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 12, 12, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " dropout_4 (Dropout)         (None, 12, 12, 32)        0         \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 4608)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               589952    \n",
      "                                                                 \n",
      " activation_10 (Activation)  (None, 128)               0         \n",
      "                                                                 \n",
      " dropout_5 (Dropout)         (None, 128)               0         \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 5)                 645       \n",
      "                                                                 \n",
      " activation_11 (Activation)  (None, 5)                 0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 600,165\n",
      "Trainable params: 600,165\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c27e965d-d00e-44d0-b80c-b74abdd6d333",
   "metadata": {},
   "source": [
    "#### Training the model on digits 5-9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "324c7cdc-6b34-4ebd-918e-4fe18472848d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (29404, 28, 28, 1)\n",
      "29404 train samples\n",
      "4861 test samples\n",
      "Epoch 1/5\n",
      "230/230 [==============================] - 15s 66ms/step - loss: 1.5963 - accuracy: 0.2450 - val_loss: 1.5748 - val_accuracy: 0.3063\n",
      "Epoch 2/5\n",
      "230/230 [==============================] - 16s 68ms/step - loss: 1.5645 - accuracy: 0.3002 - val_loss: 1.5392 - val_accuracy: 0.3658\n",
      "Epoch 3/5\n",
      "230/230 [==============================] - 16s 69ms/step - loss: 1.5317 - accuracy: 0.3709 - val_loss: 1.5010 - val_accuracy: 0.4931\n",
      "Epoch 4/5\n",
      "230/230 [==============================] - 17s 75ms/step - loss: 1.4949 - accuracy: 0.4466 - val_loss: 1.4590 - val_accuracy: 0.5803\n",
      "Epoch 5/5\n",
      "230/230 [==============================] - 17s 75ms/step - loss: 1.4537 - accuracy: 0.5149 - val_loss: 1.4116 - val_accuracy: 0.6429\n",
      "Training time: 0:01:21.476132\n",
      "152/152 [==============================] - 1s 4ms/step - loss: 1.4116 - accuracy: 0.6429\n",
      "Test score: 1.4116288423538208\n",
      "Test accuracy: 0.6428718566894531\n"
     ]
    }
   ],
   "source": [
    "train_model(model,(X_train_gte5, y_train_gte5),(X_test_gte5, y_test_gte5), num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a45973-d3ab-45a6-8077-11fcb80eeb8c",
   "metadata": {},
   "source": [
    "#### Freezing layers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a406058-96f7-4b62-8ce6-5dcd97280360",
   "metadata": {},
   "source": [
    "Keras allows layers to be \"frozen\" during the training process.  That is, some layers would have their weights updated during the training process, while others would not.  This is a core part of transfer learning, the ability to train just the last one or several layers.\n",
    "\n",
    "Note also, that a lot of the training time is spent \"back-propagating\" the gradients back to the first layer.  Therefore, if we only need to compute the gradients back a small number of layers, the training time is much quicker per iteration.  This is in addition to the savings gained by being able to train on a smaller data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "738095be-8d7e-40d3-b59d-0300dffe0422",
   "metadata": {},
   "outputs": [],
   "source": [
    "for l in feature_layers:\n",
    "    l.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "420d8d4a-bd55-443f-874b-9dd0b846f8cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (30596, 28, 28, 1)\n",
      "30596 train samples\n",
      "5139 test samples\n",
      "Epoch 1/5\n",
      "240/240 [==============================] - 6s 21ms/step - loss: 1.5890 - accuracy: 0.2690 - val_loss: 1.5675 - val_accuracy: 0.4024\n",
      "Epoch 2/5\n",
      "240/240 [==============================] - 4s 16ms/step - loss: 1.5602 - accuracy: 0.3416 - val_loss: 1.5361 - val_accuracy: 0.4670\n",
      "Epoch 3/5\n",
      "240/240 [==============================] - 4s 19ms/step - loss: 1.5301 - accuracy: 0.4044 - val_loss: 1.5050 - val_accuracy: 0.5334\n",
      "Epoch 4/5\n",
      "240/240 [==============================] - 4s 19ms/step - loss: 1.5016 - accuracy: 0.4542 - val_loss: 1.4735 - val_accuracy: 0.5943\n",
      "Epoch 5/5\n",
      "240/240 [==============================] - 4s 18ms/step - loss: 1.4733 - accuracy: 0.5022 - val_loss: 1.4418 - val_accuracy: 0.6573\n",
      "Training time: 0:00:22.744790\n",
      "161/161 [==============================] - 1s 4ms/step - loss: 1.4418 - accuracy: 0.6573\n",
      "Test score: 1.4418450593948364\n",
      "Test accuracy: 0.657326340675354\n"
     ]
    }
   ],
   "source": [
    "train_model(model,(X_train_lt5, y_train_lt5),(X_test_lt5, y_test_lt5), num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ca7a7d-2dc8-4ec0-837a-5f05bbf406e3",
   "metadata": {},
   "source": [
    "#### Conclusion: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9799deb9-8ad0-4f6c-84d4-ca2ceaf78458",
   "metadata": {},
   "source": [
    "Transfer learning is useful when we are training images that are similar to one another. We use the beggining layers, freeze certain layers \n",
    "as a reguarlization technique, and only train on the last few layers since that is where most of the learning is taking place. This speeds\n",
    "up training and gives an accuracy when classifying images similar to a typical CNN at a much faster rate. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

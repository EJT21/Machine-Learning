{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c842ccdc-c6c8-4147-9706-4b8e44be8f44",
   "metadata": {},
   "source": [
    "## Auto Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6def098e-c50f-41c4-9396-d7d6214c2824",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25b1729-59e0-4d61-97f8-2741d34bad6a",
   "metadata": {},
   "source": [
    "### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df2ecf0d-b993-4e61-acde-7fa5e2154034",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv('ml-1m/movies.dat', sep='::', header=None, engine='python', encoding='latin-1')\n",
    "users = pd.read_csv('ml-1m/users.dat', sep='::', header=None, engine='python', encoding='latin-1')\n",
    "ratings = pd.read_csv('ml-1m/ratings.dat', sep='::', header=None, engine='python', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3853890d-92b8-482e-9375-709cf52a41d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children's|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                                   1                             2\n",
       "0  1                    Toy Story (1995)   Animation|Children's|Comedy\n",
       "1  2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
       "2  3             Grumpier Old Men (1995)                Comedy|Romance\n",
       "3  4            Waiting to Exhale (1995)                  Comedy|Drama\n",
       "4  5  Father of the Bride Part II (1995)                        Comedy"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9296a320-3f05-422e-93c5-092dadf1c56b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>56</td>\n",
       "      <td>16</td>\n",
       "      <td>70072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>55117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>45</td>\n",
       "      <td>7</td>\n",
       "      <td>02460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>55455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1   2   3      4\n",
       "0  1  F   1  10  48067\n",
       "1  2  M  56  16  70072\n",
       "2  3  M  25  15  55117\n",
       "3  4  M  45   7  02460\n",
       "4  5  M  25  20  55455"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "05f6fb98-b4b4-4e23-9a10-32c6f559bdb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1  2          3\n",
       "0  1  1193  5  978300760\n",
       "1  1   661  3  978302109\n",
       "2  1   914  3  978301968\n",
       "3  1  3408  4  978300275\n",
       "4  1  2355  5  978824291"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ad66fe5-e2bb-4a24-93da-2b7e46f0a200",
   "metadata": {},
   "source": [
    "***User 1 rated movie 1193 a 5/5. The last column is a timestamp***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca168e3-7856-4709-bdcf-05345d018ba7",
   "metadata": {},
   "source": [
    "### Preparing training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fbd3057-1a5c-42fa-9e0a-74cdcbb63a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = pd.read_csv('ml-100k/u1.base', sep='\\t')\n",
    "training_set = np.array(training_set, dtype = 'int') #we need to convert int so we can use pytorch tensors\n",
    "test_set = pd.read_csv('ml-100k/u1.test', delimiter = '\\t')\n",
    "test_set = np.array(test_set, dtype = 'int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "87f01f56-64c1-4948-9156-cbea0c3632dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[        1,         2,         3, 876893171],\n",
       "       [        1,         3,         4, 878542960],\n",
       "       [        1,         4,         3, 876893119],\n",
       "       ...,\n",
       "       [      943,      1188,         3, 888640250],\n",
       "       [      943,      1228,         3, 888640275],\n",
       "       [      943,      1330,         3, 888692465]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b946765e-7a7f-4373-bb0d-cf079e10ad60",
   "metadata": {},
   "source": [
    "### Getting the number of users and movies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f72d2c-08a8-44d2-bb4e-dc8d445989f7",
   "metadata": {},
   "source": [
    "***We want the max of users in the training and test***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b08b879-ec84-4478-8b76-93c3d8ebe16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_users = int(max(max(training_set[:, 0], ), max(test_set[:, 0]))) #total number of users\n",
    "nb_movies = int(max(max(training_set[:, 1], ), max(test_set[:, 1])))#total number of movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd86650f-5a1d-46b4-bb9e-c7af86e6ef67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "943"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1b286fc0-def2-47cd-a84e-52bb08296869",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1682"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_movies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e52ac45-ddfb-48a7-81c9-eb5aac930e1e",
   "metadata": {},
   "source": [
    "***This is the max users and movies for this training set***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ebd99e-3cc6-4492-9bd6-19312e85fb92",
   "metadata": {},
   "source": [
    "### Converting the data into an array with users in lines and movies in columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "95079fba-9115-462b-9348-498068e8f7fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(data): \n",
    "    \"\"\"\n",
    "    This creates a list of lists. This will create a obseration of each user for the movies they have seen, we will \n",
    "    mark unseen movies as zero.\n",
    "    \"\"\"\n",
    "    new_data = [] #initialize a new list\n",
    "    for id_users in range(1,nb_users+1): #create a list for each user. We want to consider all users so we add a +1\n",
    "        id_movies = data[:,1][data[:,0] == id_users]  #contains all indexs of movies that were rated\n",
    "        id_ratings = data[:,2][data[:,0] == id_users] #we will get all the id_users for each ratings\n",
    "        ratings = np.zeros(nb_movies) #we zero out all the movies, if someone rated it, we replace it\n",
    "        ratings[id_movies-1] = id_ratings #we have this from id_movies. We need to start at 0 since this is a list\n",
    "        new_data.append(ratings)\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5f8b8438-e3a5-41b4-9333-fcd2a2c0ecb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set = convert(training_set)\n",
    "test_set = convert(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d1cbf0af-656d-4335-a6ca-28a90e6323ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  0 ratings of movies [0. 3. 4. ... 0. 0. 0.]\n",
      "User:  1 ratings of movies [4. 0. 0. ... 0. 0. 0.]\n",
      "User:  2 ratings of movies [0. 0. 0. ... 0. 0. 0.]\n",
      "User:  3 ratings of movies [0. 0. 0. ... 0. 0. 0.]\n",
      "User:  4 ratings of movies [0. 0. 0. ... 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print('User: ',i,'ratings of movies',training_set[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1147b44f-3ef1-481d-9bed-968f442fbc52",
   "metadata": {},
   "source": [
    "### Converting the data into torch tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92931520-9bca-4e00-bc06-4bb0e43ea375",
   "metadata": {},
   "source": [
    "***Tensors are multidimensional matrixes, which we will need for this type of data***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f561e69b-74b3-49b3-aa58-1bddf21113b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-14-bb104056638d>:1: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at  /Users/runner/work/_temp/anaconda/conda-bld/pytorch_1656352448001/work/torch/csrc/utils/tensor_new.cpp:204.)\n",
      "  training_set = torch.FloatTensor(training_set) #This argument takes a list of lists. This is why we created the convert method\n"
     ]
    }
   ],
   "source": [
    "training_set = torch.FloatTensor(training_set) #This argument takes a list of lists. This is why we created the convert method\n",
    "test_set = torch.FloatTensor(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec2ba0f8-f99a-43fc-8dac-da6ed504904b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User:  0 ratings of movies tensor([0., 3., 4.,  ..., 0., 0., 0.])\n",
      "User:  1 ratings of movies tensor([4., 0., 0.,  ..., 0., 0., 0.])\n",
      "User:  2 ratings of movies tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "User:  3 ratings of movies tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "User:  4 ratings of movies tensor([0., 0., 0.,  ..., 0., 0., 0.])\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print('User: ',i,'ratings of movies',training_set[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadd9c3f-cb16-47f0-b3c6-e9c5bd6d2533",
   "metadata": {},
   "source": [
    "### Creating the architecture of a Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "63eb5005-8dd4-440a-aa1b-67986ee242fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAE(nn.Module):\n",
    "    def __init__(self, ):\n",
    "        super(SAE, self).__init__() #we want inheritence of the parent class\n",
    "        self.fc1 = nn.Linear(nb_movies, 20) #first full connection to our autoencoder. The first input feature is the # of movies, second input is the amount of nodes we create. We experiment with this\n",
    "        self.fc2 = nn.Linear(20, 10) #we want 10 neurons in the second layer based on the previous connection we made\n",
    "        self.fc3 = nn.Linear(10, 20) #now we are doing some deconstruction\n",
    "        self.fc4 = nn.Linear(20, nb_movies) #more deconstruction\n",
    "        self.activation = nn.Sigmoid()\n",
    "    def forward(self, x): #this will do the forward propogation, x is our input vector of features\n",
    "        x = self.activation(self.fc1(x)) #we are taking the input vector of features and transforming it\n",
    "        x = self.activation(self.fc2(x))\n",
    "        x = self.activation(self.fc3(x))\n",
    "        x = self.fc4(x) #specificity of the auto-encoders, we do not need to use activation on last connection, this is now a vector of predicted ratings\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1701ebf8-b90c-49ec-83bb-a9bba400b998",
   "metadata": {},
   "outputs": [],
   "source": [
    "sae = SAE()\n",
    "criterion = nn.MSELoss() #we will use this to measure the mean squared error, this comes from nn module\n",
    "optimizer = optim.RMSprop(sae.parameters(), lr=0.01, weight_decay=0.5) #we need to input paramters, learning rate, decay: regulate convergence"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fc4d354-c9c9-45d9-9c2f-2cc9a49c9ab1",
   "metadata": {},
   "source": [
    "### Training the SAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c78a7fec-e971-404f-aefb-95f697c215cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 loss: tensor(1.0966)\n",
      "epoch: 2 loss: tensor(1.0534)\n",
      "epoch: 3 loss: tensor(1.0384)\n",
      "epoch: 4 loss: tensor(1.0308)\n",
      "epoch: 5 loss: tensor(1.0264)\n",
      "epoch: 6 loss: tensor(1.0241)\n",
      "epoch: 7 loss: tensor(1.0216)\n",
      "epoch: 8 loss: tensor(1.0207)\n",
      "epoch: 9 loss: tensor(1.0194)\n",
      "epoch: 10 loss: tensor(1.0189)\n",
      "epoch: 11 loss: tensor(1.0185)\n",
      "epoch: 12 loss: tensor(1.0178)\n",
      "epoch: 13 loss: tensor(1.0175)\n",
      "epoch: 14 loss: tensor(1.0172)\n",
      "epoch: 15 loss: tensor(1.0170)\n",
      "epoch: 16 loss: tensor(1.0166)\n",
      "epoch: 17 loss: tensor(1.0164)\n",
      "epoch: 18 loss: tensor(1.0161)\n",
      "epoch: 19 loss: tensor(1.0161)\n",
      "epoch: 20 loss: tensor(1.0158)\n",
      "epoch: 21 loss: tensor(1.0159)\n",
      "epoch: 22 loss: tensor(1.0159)\n",
      "epoch: 23 loss: tensor(1.0159)\n",
      "epoch: 24 loss: tensor(1.0156)\n",
      "epoch: 25 loss: tensor(1.0155)\n",
      "epoch: 26 loss: tensor(1.0152)\n",
      "epoch: 27 loss: tensor(1.0150)\n",
      "epoch: 28 loss: tensor(1.0139)\n",
      "epoch: 29 loss: tensor(1.0122)\n",
      "epoch: 30 loss: tensor(1.0097)\n",
      "epoch: 31 loss: tensor(1.0098)\n",
      "epoch: 32 loss: tensor(1.0056)\n",
      "epoch: 33 loss: tensor(1.0050)\n",
      "epoch: 34 loss: tensor(1.0021)\n",
      "epoch: 35 loss: tensor(1.0007)\n",
      "epoch: 36 loss: tensor(0.9984)\n",
      "epoch: 37 loss: tensor(0.9974)\n",
      "epoch: 38 loss: tensor(0.9931)\n",
      "epoch: 39 loss: tensor(0.9913)\n",
      "epoch: 40 loss: tensor(0.9906)\n",
      "epoch: 41 loss: tensor(0.9904)\n",
      "epoch: 42 loss: tensor(0.9874)\n",
      "epoch: 43 loss: tensor(0.9894)\n",
      "epoch: 44 loss: tensor(0.9832)\n",
      "epoch: 45 loss: tensor(0.9847)\n",
      "epoch: 46 loss: tensor(0.9846)\n",
      "epoch: 47 loss: tensor(0.9798)\n",
      "epoch: 48 loss: tensor(0.9783)\n",
      "epoch: 49 loss: tensor(0.9775)\n",
      "epoch: 50 loss: tensor(0.9745)\n",
      "epoch: 51 loss: tensor(0.9739)\n",
      "epoch: 52 loss: tensor(0.9747)\n",
      "epoch: 53 loss: tensor(0.9773)\n",
      "epoch: 54 loss: tensor(0.9688)\n",
      "epoch: 55 loss: tensor(0.9737)\n",
      "epoch: 56 loss: tensor(0.9704)\n",
      "epoch: 57 loss: tensor(0.9723)\n",
      "epoch: 58 loss: tensor(0.9705)\n",
      "epoch: 59 loss: tensor(0.9692)\n",
      "epoch: 60 loss: tensor(0.9677)\n",
      "epoch: 61 loss: tensor(0.9644)\n",
      "epoch: 62 loss: tensor(0.9622)\n",
      "epoch: 63 loss: tensor(0.9616)\n",
      "epoch: 64 loss: tensor(0.9618)\n",
      "epoch: 65 loss: tensor(0.9607)\n",
      "epoch: 66 loss: tensor(0.9586)\n",
      "epoch: 67 loss: tensor(0.9579)\n",
      "epoch: 68 loss: tensor(0.9553)\n",
      "epoch: 69 loss: tensor(0.9565)\n",
      "epoch: 70 loss: tensor(0.9530)\n",
      "epoch: 71 loss: tensor(0.9593)\n",
      "epoch: 72 loss: tensor(0.9551)\n",
      "epoch: 73 loss: tensor(0.9514)\n",
      "epoch: 74 loss: tensor(0.9484)\n",
      "epoch: 75 loss: tensor(0.9481)\n",
      "epoch: 76 loss: tensor(0.9470)\n",
      "epoch: 77 loss: tensor(0.9476)\n",
      "epoch: 78 loss: tensor(0.9458)\n",
      "epoch: 79 loss: tensor(0.9469)\n",
      "epoch: 80 loss: tensor(0.9462)\n",
      "epoch: 81 loss: tensor(0.9485)\n",
      "epoch: 82 loss: tensor(0.9494)\n",
      "epoch: 83 loss: tensor(0.9485)\n",
      "epoch: 84 loss: tensor(0.9470)\n",
      "epoch: 85 loss: tensor(0.9460)\n",
      "epoch: 86 loss: tensor(0.9437)\n",
      "epoch: 87 loss: tensor(0.9438)\n",
      "epoch: 88 loss: tensor(0.9409)\n",
      "epoch: 89 loss: tensor(0.9415)\n",
      "epoch: 90 loss: tensor(0.9401)\n",
      "epoch: 91 loss: tensor(0.9413)\n",
      "epoch: 92 loss: tensor(0.9440)\n",
      "epoch: 93 loss: tensor(0.9431)\n",
      "epoch: 94 loss: tensor(0.9420)\n",
      "epoch: 95 loss: tensor(0.9417)\n",
      "epoch: 96 loss: tensor(0.9411)\n",
      "epoch: 97 loss: tensor(0.9413)\n",
      "epoch: 98 loss: tensor(0.9394)\n",
      "epoch: 99 loss: tensor(0.9442)\n",
      "epoch: 100 loss: tensor(0.9413)\n",
      "epoch: 101 loss: tensor(0.9429)\n",
      "epoch: 102 loss: tensor(0.9405)\n",
      "epoch: 103 loss: tensor(0.9400)\n",
      "epoch: 104 loss: tensor(0.9369)\n",
      "epoch: 105 loss: tensor(0.9391)\n",
      "epoch: 106 loss: tensor(0.9364)\n",
      "epoch: 107 loss: tensor(0.9350)\n",
      "epoch: 108 loss: tensor(0.9372)\n",
      "epoch: 109 loss: tensor(0.9365)\n",
      "epoch: 110 loss: tensor(0.9346)\n",
      "epoch: 111 loss: tensor(0.9347)\n",
      "epoch: 112 loss: tensor(0.9332)\n",
      "epoch: 113 loss: tensor(0.9332)\n",
      "epoch: 114 loss: tensor(0.9310)\n",
      "epoch: 115 loss: tensor(0.9324)\n",
      "epoch: 116 loss: tensor(0.9315)\n",
      "epoch: 117 loss: tensor(0.9337)\n",
      "epoch: 118 loss: tensor(0.9394)\n",
      "epoch: 119 loss: tensor(0.9366)\n",
      "epoch: 120 loss: tensor(0.9346)\n",
      "epoch: 121 loss: tensor(0.9356)\n",
      "epoch: 122 loss: tensor(0.9325)\n",
      "epoch: 123 loss: tensor(0.9327)\n",
      "epoch: 124 loss: tensor(0.9305)\n",
      "epoch: 125 loss: tensor(0.9316)\n",
      "epoch: 126 loss: tensor(0.9293)\n",
      "epoch: 127 loss: tensor(0.9305)\n",
      "epoch: 128 loss: tensor(0.9285)\n",
      "epoch: 129 loss: tensor(0.9298)\n",
      "epoch: 130 loss: tensor(0.9281)\n",
      "epoch: 131 loss: tensor(0.9286)\n",
      "epoch: 132 loss: tensor(0.9272)\n",
      "epoch: 133 loss: tensor(0.9284)\n",
      "epoch: 134 loss: tensor(0.9266)\n",
      "epoch: 135 loss: tensor(0.9280)\n",
      "epoch: 136 loss: tensor(0.9263)\n",
      "epoch: 137 loss: tensor(0.9273)\n",
      "epoch: 138 loss: tensor(0.9257)\n",
      "epoch: 139 loss: tensor(0.9265)\n",
      "epoch: 140 loss: tensor(0.9252)\n",
      "epoch: 141 loss: tensor(0.9260)\n",
      "epoch: 142 loss: tensor(0.9240)\n",
      "epoch: 143 loss: tensor(0.9248)\n",
      "epoch: 144 loss: tensor(0.9236)\n",
      "epoch: 145 loss: tensor(0.9244)\n",
      "epoch: 146 loss: tensor(0.9233)\n",
      "epoch: 147 loss: tensor(0.9240)\n",
      "epoch: 148 loss: tensor(0.9239)\n",
      "epoch: 149 loss: tensor(0.9243)\n",
      "epoch: 150 loss: tensor(0.9221)\n",
      "epoch: 151 loss: tensor(0.9233)\n",
      "epoch: 152 loss: tensor(0.9218)\n",
      "epoch: 153 loss: tensor(0.9237)\n",
      "epoch: 154 loss: tensor(0.9220)\n",
      "epoch: 155 loss: tensor(0.9231)\n",
      "epoch: 156 loss: tensor(0.9207)\n",
      "epoch: 157 loss: tensor(0.9217)\n",
      "epoch: 158 loss: tensor(0.9202)\n",
      "epoch: 159 loss: tensor(0.9214)\n",
      "epoch: 160 loss: tensor(0.9198)\n",
      "epoch: 161 loss: tensor(0.9215)\n",
      "epoch: 162 loss: tensor(0.9190)\n",
      "epoch: 163 loss: tensor(0.9204)\n",
      "epoch: 164 loss: tensor(0.9186)\n",
      "epoch: 165 loss: tensor(0.9206)\n",
      "epoch: 166 loss: tensor(0.9200)\n",
      "epoch: 167 loss: tensor(0.9200)\n",
      "epoch: 168 loss: tensor(0.9183)\n",
      "epoch: 169 loss: tensor(0.9195)\n",
      "epoch: 170 loss: tensor(0.9178)\n",
      "epoch: 171 loss: tensor(0.9189)\n",
      "epoch: 172 loss: tensor(0.9174)\n",
      "epoch: 173 loss: tensor(0.9188)\n",
      "epoch: 174 loss: tensor(0.9175)\n",
      "epoch: 175 loss: tensor(0.9186)\n",
      "epoch: 176 loss: tensor(0.9169)\n",
      "epoch: 177 loss: tensor(0.9180)\n",
      "epoch: 178 loss: tensor(0.9167)\n",
      "epoch: 179 loss: tensor(0.9178)\n",
      "epoch: 180 loss: tensor(0.9161)\n",
      "epoch: 181 loss: tensor(0.9176)\n",
      "epoch: 182 loss: tensor(0.9164)\n",
      "epoch: 183 loss: tensor(0.9173)\n",
      "epoch: 184 loss: tensor(0.9157)\n",
      "epoch: 185 loss: tensor(0.9165)\n",
      "epoch: 186 loss: tensor(0.9152)\n",
      "epoch: 187 loss: tensor(0.9164)\n",
      "epoch: 188 loss: tensor(0.9153)\n",
      "epoch: 189 loss: tensor(0.9160)\n",
      "epoch: 190 loss: tensor(0.9147)\n",
      "epoch: 191 loss: tensor(0.9163)\n",
      "epoch: 192 loss: tensor(0.9148)\n",
      "epoch: 193 loss: tensor(0.9155)\n",
      "epoch: 194 loss: tensor(0.9141)\n",
      "epoch: 195 loss: tensor(0.9150)\n",
      "epoch: 196 loss: tensor(0.9138)\n",
      "epoch: 197 loss: tensor(0.9148)\n",
      "epoch: 198 loss: tensor(0.9138)\n",
      "epoch: 199 loss: tensor(0.9148)\n",
      "epoch: 200 loss: tensor(0.9126)\n"
     ]
    }
   ],
   "source": [
    "nb_epoch = 200 #we can choose more or less\n",
    "for epoch in range(1, nb_epoch + 1): #in each epoch, we will loop over each observation. One loop to loop over each epoch, the other to loop over. each user\n",
    "    train_loss = 0 #we need to keep track of the loss\n",
    "    s = 0. #this will be used to compute the root squared mean error\n",
    "    for id_user in range(nb_users): #this will loop over all the users\n",
    "        input = Variable(training_set[id_user]).unsqueeze(0) #this is a vector of 1 dimension, so I modified it by adding another dimension. This is the batch\n",
    "        target = input.clone() #we want to now create the target\n",
    "        if torch.sum(target.data > 0)> 0: #this will only look at users who rated at least one movie. This will save us a lot of memory\n",
    "            output =  sae(input) #we want a vector of predicted ratings. This will call the forward method in the sae class\n",
    "            target.require_grad = False #we dont want to compute gradient descent for target since we already are for input\n",
    "            output[target == 0] = 0 #we want to not include movie ratings that a user didnt see when calcuating error\n",
    "            loss = criterion(output, target) #this computes the loss error. Input is real and predicted\n",
    "            mean_corrector = nb_movies/float(torch.sum(target.data > 0) + 1e-10) #we only want movies that have non zero ratings. This last part makes sure our den is never zero, avoid infinte computation\n",
    "            loss.backward() #we will call the backward method, this increases or decreases weights, decides direction\n",
    "            train_loss += np.sqrt(loss.data*mean_corrector) #updating the train/loss\n",
    "            s += 1.\n",
    "            optimizer.step() #this will apply optimizer to update weights. This decides the intensity of the weights\n",
    "    print('epoch: '+str(epoch)+' loss: '+str(train_loss/s))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acbc5af9-d185-4cac-b8d8-9134f9d81467",
   "metadata": {},
   "source": [
    "***We can expect a difference of .91 between each rating on average***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d194a08a-3602-4a61-a573-5b16c5ff6139",
   "metadata": {},
   "source": [
    "### Testing the SAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "145c2275-a9a9-4ac6-ada9-f4dcbda6379e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: tensor(0.9530)\n"
     ]
    }
   ],
   "source": [
    "test_loss = 0 \n",
    "s = 0. \n",
    "for id_user in range(nb_users): \n",
    "        input = Variable(training_set[id_user]).unsqueeze(0) \n",
    "        target = Variable(test_set[id_user]).unsqueeze(0) #the real ratings of the test set\n",
    "        if torch.sum(target.data > 0)> 0: \n",
    "            output =  sae(input) \n",
    "            target.require_grad = False \n",
    "            output[target == 0] = 0 \n",
    "            loss = criterion(output, target) \n",
    "            mean_corrector = nb_movies/float(torch.sum(target.data > 0) + 1e-10) \n",
    "            test_loss += np.sqrt(loss.data*mean_corrector) \n",
    "            s += 1.\n",
    "print('loss: '+str(test_loss/s))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44aae45e-504c-4741-ba85-7c50677e991f",
   "metadata": {},
   "source": [
    "***We predicted the test set with a difference of .95 between each rating on average***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71866411-d29c-4cb2-a846-7d0b0c6e8d88",
   "metadata": {},
   "source": [
    "### Predicitons for a single user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "30911fd9-5e6c-40f1-8f70-7f4318405b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = 0\n",
    "movie_title = movies.iloc[:nb_movies, 1:2]\n",
    "user_rating = training_set.data.numpy()[user_id, :].reshape(-1,1)\n",
    "user_target = test_set.data.numpy()[user_id, :].reshape(-1,1)\n",
    " \n",
    "user_input = Variable(training_set[user_id]).unsqueeze(0)\n",
    "predicted = sae(user_input)\n",
    "predicted = predicted.data.numpy().reshape(-1,1)\n",
    " \n",
    "# Join all info in one dataset\n",
    "result_array = np.hstack([movie_title, user_target, predicted])\n",
    "result_array = result_array[result_array[:, 1] > 0]\n",
    "result_df = pd.DataFrame(data=result_array, columns=['Movie', 'Target Rating', 'Predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "707c8606-dbc0-49c4-b32c-7ba371059bf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Movie</th>\n",
       "      <th>Target Rating</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GoldenEye (1995)</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.876193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dracula: Dead and Loving It (1995)</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.519506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nixon (1995)</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.009555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sense and Sensibility (1995)</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.28435</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Money Train (1995)</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.493617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>Legends of the Fall (1994)</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.84911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>Major Payne (1994)</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.160089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>Little Odessa (1994)</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.43795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>My Crazy Life (Mi vida loca) (1993)</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.576608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>Man of the House (1995)</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.20473</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>136 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   Movie Target Rating Predicted\n",
       "0                       GoldenEye (1995)           3.0  3.876193\n",
       "1     Dracula: Dead and Loving It (1995)           5.0  4.519506\n",
       "2                           Nixon (1995)           5.0  4.009555\n",
       "3           Sense and Sensibility (1995)           3.0   3.28435\n",
       "4                     Money Train (1995)           4.0  3.493617\n",
       "..                                   ...           ...       ...\n",
       "131           Legends of the Fall (1994)           2.0   2.84911\n",
       "132                   Major Payne (1994)           4.0  4.160089\n",
       "133                 Little Odessa (1994)           1.0   2.43795\n",
       "134  My Crazy Life (Mi vida loca) (1993)           4.0  2.576608\n",
       "135              Man of the House (1995)           3.0   4.20473\n",
       "\n",
       "[136 rows x 3 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c449c703-ee7e-4edb-b006-dd4ecc9e3d63",
   "metadata": {},
   "source": [
    "***The person with user id = 0 is pritned with their movie ratings and what the model predicted it would be***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5abb7976-1410-4479-95b3-67b4248c1b3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
